[PT-BR] Para a vers√£o em portugu√™s deste documento, role at√© o final da p√°gina.

---

# Optimized Report Generator for PV Plant Logs

![Python](https://img.shields.io/badge/Python-3.x-blue.svg?style=for-the-badge&logo=python)
![Tkinter](https://img.shields.io/badge/Tkinter-GUI-orange.svg?style=for-the-badge&logo=python)
![Pandas](https://img.shields.io/badge/Pandas-Data%20Processing-green.svg?style=for-the-badge&logo=pandas)
![Threads](https://img.shields.io/badge/Architecture-Multi--Threading-informational.svg?style=for-the-badge)

> **‚ö†Ô∏è Confidentiality Note:** This is a case study of a proprietary project. Sensitive details such as IPs, FTP access credentials, and plant data have been omitted for security and confidentiality reasons.

---

### üéØ Project Goal

The objective of this project was to develop a robust desktop application to completely automate the process of downloading, processing, and consolidating log data from photovoltaic plants. The tool was designed to replace a slow and error-prone manual process, serving as a centralized solution for report generation.

---

### üìà The Scenario: A Daily Operational Challenge

The manual consolidation of log data from multiple photovoltaic plants was an inefficient and complex process. The task involved:

* **Manual connection** to multiple FTP servers.
* **Navigation through complex folder structures** to locate the correct files for a specific period.
* **Downloading hundreds of individual `.csv` files**.
* **Manual processing and consolidation** of the data, a repetitive task with a high risk of human error.

This workflow consumed significant time and made large-scale data analysis difficult.

---

### ‚ú® The Solution: A Desktop Application with Python

To solve this problem, I developed a complete application with a graphical user interface (GUI) that automates and optimizes the entire process. The tool was built with the following technical features:

* **‚úÖ Complete Graphical User Interface with `Tkinter`:**
    * I developed a GUI that allows the user to build a report queue by intuitively selecting plants and time periods. It is possible to manage the queue, remove tasks, or clear the entire list before processing.

* **‚úÖ Parallel Architecture with Multi-Threading:**
    * The application uses a pool of `threads` to process multiple plants simultaneously, which drastically accelerates the total processing time for a batch and keeps the graphical interface always responsive, displaying the status in real-time without ever freezing.

* **‚úÖ Intelligent and "On-Demand" Download via FTP:**
    * The tool implements a recursive search logic to map the directory structure on the FTP server. It then filters and selectively downloads only the minimum set of log files required for the requested period, optimizing network usage.

* **‚úÖ Data Treatment and Enrichment with `Pandas`:**
    * The core of the application not only downloads the data but also performs a deep treatment to ensure the quality of the final report:
        * **Cleaning and Correction:** Invalid or corrupt values are discarded. Numerical sensor data is treated so that negative values (physically impossible for many measurements) are set to zero, and decimal precision is standardized through rounding.
        * **Enrichment with Quality Metrics:** The final report is enriched with two crucial analysis columns: `Quality (%)`, which measures the presence of a datalogger signal over time, and `Integrity (%)`, which measures the percentage of sensor data that was effectively filled.

* **‚úÖ Intelligent Failure Recovery:**
    * A feature that allows the user to select a previously processed batch. The program reads the log file from that execution, identifies all tasks that resulted in a "Critical Failure," and automatically adds them to the current queue for a new attempt.

---

### üöÄ Results and Impact

The implementation of this tool transformed a manual and time-consuming process into an automated, fast, and reliable workflow.

| Area | Before Automation | After Automation |
| :--- | :--- | :--- |
| **Process** | Manual, sequential, and dependent on third parties | Automated, parallel, and self-contained |
| **Execution Time**| **~3 days per plant** (including request and collection) | **~15 minutes for the complete batch** of all plants |
| **Data Quality** | Raw, noisy data with gaps | Treated, clean, continuous data enriched with metadata |
| **Reliability** | High risk of copy and consolidation errors | Generation of consistent reports with failure handling |

The main result was the transformation of an analysis cycle that took days into a process executed in minutes, delivering not only speed but also a higher quality data product.

---

### üí° Skills and Competencies Demonstrated

* **Desktop Software Development:** Building a standalone application with `Tkinter`.
* **Concurrent Software Architecture:** Designing and implementing a multi-threaded system for parallel processing, using `threading` and `queue` for safe communication.
* **Network Communication:** Using the `ftplib` library to interact with FTP servers, navigate remote directories, and transfer files.
* **Data Engineering:** Implementing an ETL (Extract, Transform, Load) pipeline with `Pandas` and `NumPy` to read, clean, group, format, and enrich large volumes of time-series data.
* **UI/UX Design:** Creating a functional interface focused on user experience, including real-time feedback and error recovery features.


&nbsp;
&nbsp;

---
---
&nbsp;
&nbsp;

## **Vers√£o em Portugu√™s**

---


# Gerador de Relat√≥rios Otimizado para Logs de UFV

![Python](https://img.shields.io/badge/Python-3.x-blue.svg?style=for-the-badge&logo=python)
![Tkinter](https://img.shields.io/badge/Tkinter-GUI-orange.svg?style=for-the-badge&logo=python)
![Pandas](https://img.shields.io/badge/Pandas-Data%20Processing-green.svg?style=for-the-badge&logo=pandas)
![Threads](https://img.shields.io/badge/Architecture-Multi--Threading-informational.svg?style=for-the-badge)

> **‚ö†Ô∏è Nota de Confidencialidade:** Este √© um case study de um projeto propriet√°rio. Detalhes sens√≠veis como IPs, credenciais de acesso FTP e os dados das usinas foram omitidos por quest√µes de seguran√ßa e confidencialidade.

---

### üéØ Objetivo do Projeto

O objetivo deste projeto foi desenvolver uma aplica√ß√£o de desktop robusta para automatizar completamente o processo de download, processamento e consolida√ß√£o de dados de log de usinas fotovoltaicas. A ferramenta foi projetada para substituir um processo manual lento e propenso a erros, servindo como uma solu√ß√£o centralizada para a gera√ß√£o de relat√≥rios.

---

### üìà O Cen√°rio: Um Desafio Operacional Di√°rio

A consolida√ß√£o manual de dados de log de m√∫ltiplas usinas fotovoltaicas era um processo ineficiente e complexo. A tarefa envolvia:

* **Conex√£o manual** a m√∫ltiplos servidores FTP.
* **Navega√ß√£o em estruturas de pastas complexas** para localizar os arquivos corretos para um determinado per√≠odo.
* **Download de centenas de arquivos** `.csv` individuais.
* **Processamento e consolida√ß√£o manual** dos dados, uma tarefa repetitiva e com alto risco de erro humano.

Este fluxo de trabalho consumia um tempo significativo e dificultava a an√°lise de dados em larga escala.

---

### ‚ú® A Solu√ß√£o: Uma Aplica√ß√£o Desktop com Python

Para resolver este problema, desenvolvi uma aplica√ß√£o completa com interface gr√°fica (GUI) que automatiza e otimiza todo o processo. A ferramenta foi constru√≠da com os seguintes recursos t√©cnicos:

* **‚úÖ Interface Gr√°fica Completa com `Tkinter`:**
    * Desenvolvi uma GUI que permite ao usu√°rio construir uma fila de relat√≥rios, selecionando usinas e per√≠odos de forma intuitiva. √â poss√≠vel gerenciar a fila, remover tarefas ou limpar a lista antes do processamento.

* **‚úÖ Arquitetura Paralela com Multi-Threading:**
    * A aplica√ß√£o utiliza um pool de `threads` para processar v√°rias usinas simultaneamente, o que acelera drasticamente o tempo total de processamento de um lote e mant√©m a interface gr√°fica sempre responsiva, exibindo o status em tempo real sem nunca congelar.

* **‚úÖ Download Inteligente e "On-Demand" via FTP:**
    * A ferramenta implementa uma l√≥gica de busca recursiva para mapear a estrutura de diret√≥rios no servidor FTP. Ela ent√£o filtra e baixa seletivamente apenas o conjunto m√≠nimo de arquivos de log necess√°rios para o per√≠odo solicitado, otimizando o uso da rede.

* **‚úÖ Tratamento e Enriquecimento de Dados com `Pandas`:**
    * O n√∫cleo da aplica√ß√£o n√£o apenas baixa os dados, mas realiza um tratamento profundo para garantir a qualidade do relat√≥rio final:
        * **Limpeza e Corre√ß√£o:** Valores inv√°lidos ou corrompidos s√£o descartados. Dados num√©ricos de sensores s√£o tratados para que valores negativos (fisicamente imposs√≠veis para muitas medi√ß√µes) sejam zerados, e a precis√£o decimal √© padronizada atrav√©s de arredondamento.
        * **Enriquecimento com M√©tricas de Qualidade:** O relat√≥rio final √© enriquecido com duas colunas de an√°lise cruciais: `Qualidade (%)`, que mede a presen√ßa de sinal do datalogger no tempo, e `Integridade (%)`, que mede a porcentagem de dados de sensores efetivamente preenchida.

* **‚úÖ Recupera√ß√£o Inteligente de Falhas:**
    * Uma funcionalidade que permite ao usu√°rio selecionar um lote processado anteriormente. O programa l√™ o arquivo de log daquela execu√ß√£o, identifica todas as tarefas que resultaram em "Falha Cr√≠tica" e as adiciona automaticamente √† fila atual para uma nova tentativa.

---

### üöÄ Resultados e Impacto

A implementa√ß√£o desta ferramenta transformou um processo manual e demorado em um fluxo de trabalho automatizado, r√°pido e confi√°vel.

| √Årea | Antes da Automa√ß√£o | Depois da Automa√ß√£o |
| :--- | :--- | :--- |
| **Processo** | Manual, sequencial e dependente de terceiros | Automatizado, paralelo e autocontido |
| **Tempo de Execu√ß√£o**| **~3 dias por usina** (incluindo solicita√ß√£o e coleta) | **~15 minutos para o lote completo** de todas as usinas |
| **Qualidade do Dado** | Dado bruto, ruidoso e com lacunas | Dado tratado, limpo, cont√≠nuo e enriquecido com metadados |
| **Confiabilidade** | Alto risco de erros de c√≥pia e consolida√ß√£o | Gera√ß√£o de relat√≥rios consistentes com tratamento de falhas |

O principal resultado foi a transforma√ß√£o de um ciclo de an√°lise que levava dias em um processo executado em minutos, entregando n√£o apenas velocidade, mas um produto de dados de qualidade superior.

---

### üí° Habilidades e Compet√™ncias Demonstradas

* **Desenvolvimento de Software Desktop:** Constru√ß√£o de uma aplica√ß√£o `standalone` com `Tkinter`.
* **Arquitetura de Software Concorrente:** Design e implementa√ß√£o de um sistema multi-threaded para processamento paralelo, utilizando `threading` e `queue` para comunica√ß√£o segura.
* **Comunica√ß√£o de Rede:** Uso da biblioteca `ftplib` para interagir com servidores FTP, navegar em diret√≥rios remotos e transferir arquivos.
* **Engenharia de Dados:** Implementa√ß√£o de um pipeline de ETL (Extra√ß√£o, Transforma√ß√£o, Carga) com `Pandas` e `NumPy` para ler, limpar, agrupar, formatar e enriquecer grandes volumes de dados de s√©ries temporais.
* **Design de UI/UX:** Cria√ß√£o de uma interface funcional com foco na experi√™ncia do usu√°rio e funcionalidades para recupera√ß√£o de erros.
